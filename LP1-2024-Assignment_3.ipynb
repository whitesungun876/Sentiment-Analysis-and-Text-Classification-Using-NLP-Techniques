{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf3653d-e405-480b-b3dc-e8c8b981d6b8",
   "metadata": {},
   "source": [
    "# Language Processing 1, Fall 2024: Assignment 3\n",
    "Assignment 3: assigned on November 25, 2024, and to be returned: **December 9, 23:59**.\n",
    "\n",
    "Welcome to the third and last assignment for LP1. It has two parts:\n",
    "\n",
    "In the first part, you will be working further on Sentiment analysis. The goal is to test your ability to use a finetuned model for sentiment analysis and to see how it works on your corpus. Then, you will compare it to the model we worked on in the last assignment. **You can get 60 points here.**\n",
    "\n",
    "In the second part, you will work on text classification. To do that, you will build different text representations, and you will assess the performance for each of those. **You can get 50 points here.**\n",
    "\n",
    "You can get a maximum of 110 points and you need **65 points** to pass the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263851d-4373-4695-8ac5-f5e36bb7fa60",
   "metadata": {},
   "source": [
    "# Part 1 (Sentiment analysis):\n",
    "\n",
    "In this part, you will be applying sentiment analysis to the corpus that we have been working in the previous assignments. You will be working on the English version only (level 0). The goal of this part is to check how different sentiment analysis models perform in sentences from novels. We compare a simple model with a fine-tuned `distilbert` model (`distilbert-base-uncased-finetuned-sst-2-english`), just like the one you saw in class (Lecture 11).\n",
    "\n",
    "\n",
    "### Exercise 1.1 (15 points):\n",
    "\n",
    "Please get the code for sentiment analysis from the second assignment and paste it here. In the case that you did not implement this part in the second assignment, please use the Vader Sentiment Analysis package[1,2].\n",
    "\n",
    "Prepare a function that given a sentence, writes to a file the sentence and a \"P\" or \"N\", indicating whether the sentence is positive or negative.\n",
    "\n",
    "[1] https://pypi.org/project/vaderSentiment/\n",
    "\n",
    "[2] https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7341c30-421d-43b3-81b0-01b71f1adc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f11b3c-ed84-4569-8d8e-828849ee32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HER\n",
    "def filetowordlist(path, sfx):\n",
    "    words = []\n",
    "    for item in sorted(os.listdir(path)):\n",
    "        if sfx in item:\n",
    "            f=open(path + item, encoding=\"iso8859-1\")\n",
    "            lines = [line.strip() for line in f]\n",
    "            f.close()\n",
    "            wordsinfile = []\n",
    "            for l in lines:\n",
    "                sentencewords = l.split()\n",
    "                wordsinfile = wordsinfile + sentencewords\n",
    "            words.append(wordsinfile)\n",
    "    return words\n",
    "\n",
    "def log(number):\n",
    "    return np.log(number)\n",
    "    \n",
    "posreviews_all = filetowordlist(\"mix20_rand700_tokens_0211/tokens/pos/\", \".txt\")\n",
    "negreviews_all = filetowordlist(\"mix20_rand700_tokens_0211/tokens/neg/\", \".txt\")    \n",
    "\n",
    "posreviews_train = posreviews_all[:550]\n",
    "negreviews_train = negreviews_all[:550]\n",
    "\n",
    "posreviews_test  = posreviews_all[550:]\n",
    "negreviews_test  = negreviews_all[550:]\n",
    "\n",
    "poswords_train=[word for sent in posreviews_train for word in sent]\n",
    "negwords_train=[word for sent in negreviews_train for word in sent]\n",
    "\n",
    "#Vocabularies for positive and negative reviews\n",
    "pos_vocab_train = set(poswords_train)\n",
    "neg_vocab_train = set(negwords_train)\n",
    "vocab_train = pos_vocab_train.union(neg_vocab_train)\n",
    "\n",
    "#Number of types (vocabulary size)\n",
    "pos_vocab_size_train = len(pos_vocab_train)\n",
    "neg_vocab_size_train = len(neg_vocab_train)\n",
    "vocab_size_train = len(vocab_train)\n",
    "\n",
    "#Number of words (tokens)\n",
    "noposwords_train=len(poswords_train)\n",
    "nonegwords_train=len(negwords_train)\n",
    "\n",
    "#Number of reviews\n",
    "noposreviews_train=len(posreviews_train)\n",
    "nonegreviews_train=len(negreviews_train)\n",
    "\n",
    "total_reviews_train = noposreviews_train + nonegreviews_train\n",
    "\n",
    "prior_probabiolity_pos_train = np.log(noposreviews_train / total_reviews_train)\n",
    "prior_probabiolity_neg_train = np.log(nonegreviews_train / total_reviews_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pos_frequencies = Counter(poswords_train)\n",
    "neg_frequencies = Counter(negwords_train)\n",
    "\n",
    "vocab_size_train = len(vocab_train)\n",
    "noposwords_train = len(poswords_train)\n",
    "nonegwords_train = len(negwords_train)\n",
    "\n",
    "pos_logprobs = {}\n",
    "neg_logprobs = {}\n",
    "\n",
    "for word in vocab_train:\n",
    "    pos_prob = (pos_frequencies[word] + 1) / (noposwords_train + vocab_size_train)\n",
    "    pos_logprobs[word] = np.log(pos_prob)\n",
    "    \n",
    "    neg_prob = (neg_frequencies[word] + 1) / (nonegwords_train + vocab_size_train)\n",
    "    neg_logprobs[word] = np.log(neg_prob)\n",
    "\n",
    "pos_oov_word_logprob = np.log(1 / (noposwords_train + vocab_size_train))\n",
    "neg_oov_word_logprob = np.log(1 / (nonegwords_train + vocab_size_train))\n",
    "\n",
    "\n",
    "def positive_or_not(sentence):\n",
    "    log_prob_pos = prior_probabiolity_pos_train\n",
    "    log_prob_neg = prior_probabiolity_neg_train\n",
    "\n",
    "    for word in sentence.split():\n",
    "        log_prob_pos += pos_logprobs.get(word, pos_oov_word_logprob)\n",
    "        log_prob_neg += neg_logprobs.get(word, neg_oov_word_logprob)\n",
    "\n",
    "    return 'P' if log_prob_pos > log_prob_neg else 'N'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3ed19-94d7-41fe-8aac-b714decee313",
   "metadata": {},
   "source": [
    "### Exercise 1.2 (20 points):\n",
    "\n",
    "Select 100 sentences of your choice from the English corpus that you obtained in the first assignment. For each sentence, apply both Sentiment Analysis models, Naive Bayes/Vader and the finetuned BERT model. \n",
    "Also for the BERT model you should make a function that prints the results of the model and returns a \"P\" or \"N\" depending on whether the sentence is positive or negative.\n",
    "\n",
    "The result of this exercise should be a list of 100 sentences, and two lists of \"P\" and \"N\", that state whether a sentence is positive or negative, according to two different Sentiment Analysis models.\n",
    "\n",
    "Print the three lists on the screen and to a file, \"sent_comp.txt\", in the following format:\n",
    "```\n",
    "Sentence, ResNB/Vader, ResBERT \n",
    "\"Lady...\", P, P \n",
    "\"He went...\", N, P\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb6b3ec-7354-4b42-b0d0-f41dc81f0d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"How?\"\n",
      "\", N, N\n",
      "\" Egremont smiled. “Your Convention is in its bloom, or rather its bud,” he said; “all is       fresh and pure now; but a little while and it will find the fate of all popular assemblies.       You will have factions.”\n",
      "\", P, P\n",
      "\"\"And yet you want to see new lands?\" he pursued. \"What is it you want to see there?\"\n",
      "\", P, P\n",
      "\"\"Yes. Because, if women never see the serpent's face, neither do they ever scent the smell of     the paradise roses; and it will be hard for you to die without a single rose d'amour in your     pretty breast, poor little Bébée?\"\n",
      "\", N, P\n",
      "\"\"Then we must be quick.\" she answered. \"Come.\"\n",
      "\", N, P\n",
      "\"When she had thus brought him all she had, and he to please her had sat down to the simple     food, she gathered a spray of roses and set it in a pot beside him, then left him and went and     stood at a little distance, waiting, with her hands lightly crossed on her chest, to see if     there were anything that he might want.\n",
      "\", N, N\n",
      "\" “Higher!” cried Birkin. “Yes. Amazing heights of upright grandeur. It makes him so much     higher in his neighbouring collier’s eyes. He sees himself reflected in the neighbouring     opinion, like in a Brocken mist, several feet taller on the strength of the pianoforte, and he     is satisfied. He lives for the sake of that Brocken spectre, the reflection of himself in the     human opinion. You do the same. If you are of high importance to humanity you are of high     importance to yourself. That is why you work so hard at the mines. If you can produce coal to     cook five thousand dinners a day, you are five thousand times more important than if you cooked     only your own dinner.” \n",
      "\", P, P\n",
      "\"\"Eh?—no, dear. There is nothing to be done anywhere in the world without money. Look, I     cannot get a litre of nuts to sell unless I pay beforehand.\"\n",
      "\", N, N\n",
      "\"The question then was, whether Florence could trust Mr. Toots; and Florence saying, with a     smile, `Oh, yes, with her whole heart!´ it became important to find out where Mr. Toots lived.     This Florence didn't know, and the Captain had forgotten; and the Captain was telling Walter,     in the little parlour, that Mr. Toots was sure to be there soon, when in came Mr. Toots     himself. \n",
      "\", N, P\n",
      "\"\"No.\"\n",
      "\", N, N\n",
      "\"`Captain Cuttle tells me, Miss Dombey,´ he eagerly began on coming in—but stopped when he saw     her face. \n",
      "\", N, N\n",
      "\"He laughed.\n",
      "\", N, P\n",
      "\" “Yes; a reporter; they want information in London as to the real state of the country, and      this time of the year, Parliament not sitting—Ah; I understand, a flying commission and a      summer tour. Well, I often wish I were a penman; but I never could do it. I’ll read any day as long as you like, but that writing, I could never manage. My friend Morley      is a powerful hand at it. His journal circulates a good deal about here; and if as I often      tell him he would only sink his high-flying philosophy and stick to old English politics, he      might make a property of it. You’ll like to know him?”\n",
      "\", N, P\n",
      "\"The debate was concluded, after another hour, by Hortensius, and Endymion was struck by the      contrast between his first and second manner. Safe from reply, and reckless in his security,      it is not easy to describe the audacity of his retorts, or the tumult of his eloquence. Rapid,      sarcastic, humorous, picturesque, impassioned, he seemed to carry everything before him, and      to resemble his former self in nothing but the music of his voice, which lent melody to scorn,      and sometimes reached the depth of pathos.\n",
      "\", P, N\n",
      "\"`I repeat, Mrs. Dombey, does not please me. I have already taken occasion to request that it     may be corrected. I now insist upon it.´ \n",
      "\", N, N\n",
      "\" He wanted to put his arm round her. If he could put his arm round her, and draw her against     him as they walked, he would equilibriate himself. For now he felt like a pair of scales, the     half of which tips down and down into an indefinite void. He must recover some sort of balance.     And here was the hope and the perfect recovery. \n",
      "\", N, N\n",
      "\"“But am I equal to such a task?” said Endymion modestly, but sincerely.\n",
      "\", N, P\n",
      "\"`I!´ cried old woman. `To my gal! A mother dutiful to her own child!´ \n",
      "\", N, N\n",
      "\"\"Her pinafore had three rents in it, which she never thinks of mending though I gave her     needles and thread myself a week ago. But she does not know how to use them any more than a     baby.\"\n",
      "\", N, N\n",
      "\"\"Are you going to bed, George?\"\n",
      "\", N, N\n",
      "\" Advertisement\n",
      "\", N, N\n",
      "\"`James!´ cried the other, flushing in his turn. `What do you mean by these insulting words?     Why do you so basely use them to me, unprovoked?´ \n",
      "\", N, N\n",
      "\"\"These points will have to be verified.\"\n",
      "\", N, N\n",
      "\"In this way, Walter, so far from forgetting or losing sight of his acquaintance with     Florence, only remembered it better and better. As to its adventurous beginning, and all those     little circumstances which gave it a distinctive character and relish, he took them into     account, more as a pleasant story very agreeable to his imagination, and not to be dismissed     from it, than as a part of any matter of fact with which he was concerned. They set     off Florence very much, to his fancy; but not himself. Sometimes he thought (and then he walked     very fast) what a grand thing it would have been for him to have been going to sea on the day     after that first meeting, and to have gone, and to have done wonders there, and to have stopped     away a long time, and to have come back an Admiral of all the colours of the dolphin, or at     least a Post-Captain with epaulettes of insupportable brightness, and have married Florence     (then a beautiful young woman) in spite of Mr. Dombey's teeth, cravat, and watch-chain, and     borne her away to the blue shores of somewhere or other, triumphantly. But these flights of     fancy seldom burnished the brass plate of Dombey and Son's Offices into a tablet of golden     hope, or shed a brilliant lustre on their dirty skylights; and when the Captain and Uncle Sol     talked about Richard Whittington and masters´ daughters, Walter felt that he understood his     true position at Dombey and Son's much better than they did. \n",
      "\", P, P\n",
      "\" Rosalind opened the door to him. She started slightly, as a young girl will, and said: \n",
      "\", N, P\n",
      "\"The clock in the vestibule struck nine as Robert opened the library door. Alicia had just     descended the stairs with her maid; a rosy-faced country girl.\n",
      "\", P, P\n",
      "\"“He invited himself to Hainault, because he is so fond of papa,” said Adriana.\n",
      "\", P, P\n",
      "\" Gerald was her escape from the heavy slough of the pale, underworld, automatic colliers. He     started out of the mud. He was master. She saw his back, the movement of his white loins. But     not that—it was the whiteness he seemed to enclose as he bent forwards, rowing. He seemed to     stoop to something. His glistening, whitish hair seemed like the electricity of the sky. \n",
      "\", N, P\n",
      "\"`Then when you see me now,´ said Alice hoarsely, `here again, kneeling quietly on the ground,     with my touch upon your arm, with my eyes upon your face, you may believe that there is no     common earnestness in what I say, and that no common struggle has been battling in my breast. I     am ashamed to speak the words, but I relent. I despise myself; I have fought with myself all     day, and all last night; but I relent towards him without reason, and wish to repair what I     have done, if it is possible. I wouldn't have them come together while his pursuer is so blind     and headlong. If you had seen him as he went out last night, you would know the danger better.´ \n",
      "\", N, N\n",
      "\"He wished his relations good-night and good-by at about half past ten o'clock; he should run     up to London by the first train to look for George in Figtree Court.\n",
      "\", N, N\n",
      "\"`Dear little Dombey!´ murmured Mrs. Chick. \n",
      "\", N, P\n",
      "\" Lady Marney left the dining-room; the brothers were alone. Lord Marney filled a bumper,       which he drank off rapidly, pushed the bottle to his brother, and then said again, “What a       cursed bore it is that Grouse is not here.”\n",
      "\", N, N\n",
      "\" “I should be cursed sorry to be deep against him,” said the peer.\n",
      "\", N, N\n",
      "\" “There’s no need to be nasty about it,” said Gerald. \n",
      "\", N, P\n",
      "\"Then the children grew tired of asking her to play; and their elders began to shake their     heads; she was so pale and so quiet, there must be some evil in it—so they began to think.\n",
      "\", N, N\n",
      "\"A transient flush of faint surprise overspread the sick lady's face as she raised her eyes     towards him. \n",
      "\", P, P\n",
      "\"Robert Audley sat until long after daybreak with the sick man, who fell into a heavy slumber     a short time after he had finished his story. The old woman had dozed comfortably throughout     her son's confession. Phoebe was asleep upon the press bedstead in the room below; so the young     barrister was the only watcher.\n",
      "\", N, N\n",
      "\"\"Elizabeth I want you to tell me the truth about that unfortunate breakage. Don't be afraid.     I had rather you broke every thing in the house than have told me what was not true.\"\n",
      "\", N, N\n",
      "\"The Captain was greatly relieved by this reply, and expressed his satisfaction by taking off     his hard glazed hat, and dabbing his head all over with his handkerchief, rolled up like a     ball, observing several times, with infinite complacency, and with a beaming countenance, that     he know'd it. \n",
      "\", P, P\n",
      "\" “Won’t it?” “The working classes will have less to spend than ever.”\n",
      "\", N, N\n",
      "\" She strayed absorbedly on, over the brooks. She wanted to go to the mill-pond above. The big     mill-house was deserted, save for a labourer and his wife who lived in the kitchen. So she     passed through the empty farm-yard and through the wilderness of a garden, and mounted the bank     by the sluice. When she got to the top, to see the old, velvety surface of the pond before her,     she noticed a man on the bank, tinkering with a punt. It was Birkin sawing and hammering away. \n",
      "\", N, N\n",
      "\"“Oh! we do pretty well,” said Mr. Penruddock.\n",
      "\", N, P\n",
      "\"But it was not in his design that she should be glad.\n",
      "\", N, N\n",
      "\"As Withers disappeared, Mrs. Skewton turned her head languidly towards the Major, without     otherwise moving, and asked him how his friend was? \n",
      "\", N, N\n",
      "\" “Aw, there’s a difference,” he said satirically. \n",
      "\", N, P\n",
      "\"A long silence followed, broken first by the Judge, who said at last solemnly to Devaux:\n",
      "\", N, N\n",
      "\"'In that case I should have wasted my day. I think that it is a hundred to one against Smith     knowing where they live. As long as he has liquor and good pay, why should he ask questions?     They send him messages what to do. No, I thought over every possible course, and this is the     best.'\n",
      "\", N, P\n",
      "\"Could it be she?—she indeed—who had gone there the year before the gladdest thing that the     earth bore, with no care except to shelter her flowers from the wind, and keep the freshest     blossoms for the burgomaster's housewife?\n",
      "\", N, N\n",
      "\" “Gudrun! Gudrun!” she called, waving up the well of the staircase. “Shu-hu!” \n",
      "\", P, P\n",
      "\"`And—I'm sorry to give you so much trouble, Towlinson,'—said Miss Tox, looking at him     pensively. \n",
      "\", N, P\n",
      "\" “Never,” murmured Sybil.\n",
      "\", N, N\n",
      "\"\"Returned? You mean arrived.\"\n",
      "\", N, N\n",
      "\" “You terrify me,” said Sybil. “I knew we had fearful odds to combat against. My visit to       this city alone has taught me how strong are our enemies. But I believed that we had on our       side God and Truth.”\n",
      "\", P, P\n",
      "\"She turned her back upon him, and, without reply, sat down before her glass. \n",
      "\", N, N\n",
      "\"To Major Bagstock, the bankruptcy was quite a calamity. The Major was not a sympathetic     character—his attention being wholly concentrated on J.B.—nor was he a man subject to lively     emotions, except in the physical regards of gasping and choking. But he had so paraded his     friend Dombey at the club; had so flourished him at the heads of the members in general, and so     put them down by continual assertion of his riches; that the club, being but human, was     delighted to retort upon the Major, by asking him, with a show of great concern, whether this     tremendous smash had been at all expected, and how his friend Dombey bore it. To such     questions, the Major, waxing very purple, would reply that it was a bad world, Sir, altogether;     that Joey knew a thing or two, but had been done, Sir, done like an infant; that if you had     foretold this, Sir, to J. Bagstock, when he went abroad with Dombey and was chasing that     vagabond up and down France, J. Bagstock would have pooh-pooh'd you—would have pooh-pooh'd you,     Sir, by the Lord! That Joe had been deceived, Sir, taken in, hoodwinked, blindfolded, but was     broad awake again and staring; insomuch, Sir, that if Joe's father were to rise up from the     grave to-morrow, he wouldn't trust the old blade with a penny piece, but would tell him that     his son Josh was too old a soldier to be done again, Sir. That he was a suspicious, crabbed,     cranky, used-up, J.B. infidel, Sir; and that if it were consistent with the dignity of a rough     and tough old Major, of the old school, who had had the honour of being personally known to,     and commended by, their late Royal Highnesses the Dukes of Kent and York, to retire to a tub     and live in it, by Gad! Sir, he'd have a tub in Pall Mall to-morrow, to show his contempt for     mankind! \n",
      "\", N, N\n",
      "\"\"No right to be warden of the hospital, papa?\"\n",
      "\", N, N\n",
      "\" Gerald walked with his queer, long wolf-steps across the bedroom to the window, stooped and     looked out, then rose again, and turned to Gudrun, his eyes sharp with an abstract smile. He     seemed very tall to her, she saw the glisten of his whitish eyebrows, that met between his     brows. \n",
      "\", P, P\n",
      "\"'That you, Mr. Thaddeus? But who are the others? I had no orders about them from the     master.'\n",
      "\", N, N\n",
      "\"\"One or two words more,\" said the Judge to Ripaldi. \"During the journey, now, did you have     any conversation with this Quadling?\"\n",
      "\", N, N\n",
      "\"Sir Barnet Skettles immediately interposed, and said that he had had the honour of meeting     Paul's father at a public dinner, and that he hoped he was very well. Then Paul heard him say     to Lady Skettles, `City—very rich—most respectable—Doctor mentioned it.´ And then he said to     Paul, `Will you tell your good papa that Sir Barnet Skettles rejoiced to hear that he was very     well, and sent him his best compliments?´ \n",
      "\", P, P\n",
      "\"`Miss Florence,´ said Carker, `left to the care—if one may call it care—of servants and     mercenary people, in every way her inferiors, necessarily wanted some guide and compass in her     younger days, and, naturally, for want of them, has been indiscreet, and has in some degree     forgotten her station. There was some folly about one Walter, a common lad, who is fortunately     dead now: and some very undesirable association, I regret to say, with certain coasting     sailors, of anything but good repute, and a runaway old bankrupt.´ \n",
      "\", N, N\n",
      "\"\"1. I write to Alicia, proposing to take George down to the Court.\"\n",
      "\", N, P\n",
      "\" “You lean against an ancient trunk,” said Egremont, carelessly advancing to the stranger,      who looked up at him without any expression of surprise, and then replied. “They say ‘tis the      trunk beneath whose branches the monks encamped when they came to this valley to raise their      building. It was their house, till with the wood and stone around them, their labour and their      fine art, they piled up their abbey. And then they were driven out of it, and it came to this.      Poor men! poor men!”\n",
      "\", N, N\n",
      "\"“Well, I don’t know your friend,” said the young gentleman contemptuously, “so I cannot      bet.”\n",
      "\", N, N\n",
      "\"In which Christian spirit, Mrs. Chick dried her eyes, and smoothed her lap, and sat as became     a person calm under a great wrong. Mr. Chick, feeling his unworthiness no doubt, took an early     opportunity of being set down at a street corner and walking away, whistling, with his     shoulders very much raised, and his hands in his pockets. \n",
      "\", N, P\n",
      "\"Mr. Luke Marks, the hero of the occasion, thought very little of all this. He had secured the     wife of his choice, and the object of his life-long ambition—a public house. My lady had     provided the seventy-five pounds necessary for the purchase of the good-will and fixtures, with     the stock of ales and spirits, of a small inn in the center of a lonely little village, perched     on the summit of a hill, and called Mount Stanning. It was not a very pretty house to look at;     it had something of a tumble-down, weather-beaten appearance, standing, as it did, upon high     ground, sheltered only by four or five bare and overgrown poplars, that had shot up too rapidly     for their strength, and had a blighted, forlorn look in consequence. The wind had had its own     way with the Castle Inn, and had sometimes made cruel use of its power. It was the wind that     battered and bent the low, thatched roofs of outhouses and stables, till they hung over and     lurched forward, as a slouched hat hangs over the low forehead of some village ruffian; it was     the wind that shook and rattled the wooden shutters before the narrow casements, till they hung     broken and dilapidated upon their rusty hinges; it was the wind that overthrew the pigeon     house, and broke the vane that had been imprudently set up to tell the movements of its     mightiness; it was the wind that made light of any little bit of wooden trellis-work, or     creeping plant, or tiny balcony, or any modest decoration whatsoever, and tore and scattered it     in its scornful fury; it was the wind that left mossy secretions on the discolored surface of     the plaster walls; it was the wind, in short, that shattered, and ruined, and rent, and     trampled upon the tottering pile of buildings, and then flew shrieking off, to riot and glory     in its destroying strength. The dispirited proprietor grew tired of his long struggle with this     mighty enemy; so the wind was left to work its own will, and the Castle Inn fell slowly to     decay. But for all that it suffered without, it was not the less prosperous within doors.     Sturdy drovers stopped to drink at the little bar; well-to-do farmers spent their evenings and     talked politics in the low, wainscoted parlor, while their horses munched some suspicious     mixture of moldy hay and tolerable beans in the tumble-down stables. Sometimes even the members     of the Audley hunt stopped to drink and bait their horses at the Castle Inn; while, on one     grand and never-to-be-forgotten occasion, a dinner had been ordered by the master of the hounds     for some thirty gentlemen, and the proprietor driven nearly mad by the importance of the     demand.\n",
      "\", N, N\n",
      "\"\"See!\" said George, suddenly, pointing in another direction from that toward which Miss     Morley was looking, \"there's the new moon!\"\n",
      "\", N, P\n",
      "\"She laughed—a bitter laugh; but Johanna silenced it in a close embrace; and when Hilary rose     up again she was quite her natural self. She summoned Elizabeth, and began giving her all     domestic directions, just as usual; finally, bade her sister good by in a tone as like her     usual tone as possible, and left her settled on the sofa in content and peace.\n",
      "\", P, P\n",
      "\" “After the most mature reflection, prompted by a sincere solicitude for your benefit.”\n",
      "\", P, P\n",
      "\" “We will enquire into this, Sir,” said Field, “and we will take the necessary steps.”\n",
      "\", N, P\n",
      "\"\"No,\" he answered, curtly.\n",
      "\", N, N\n",
      "\" He stood still, looking at the water, and throwing upon it the husks of the flowers. \n",
      "\", N, P\n",
      "\"Endymion remained silent and confused. Imogene was some little time at the carriage-door,      for Lady Roehampton had inquiries to make after Sylvia and other courteous things to say, and      then Imogene returned, and said to Endymion, “Lady Roehampton wishes you to go with her      directly on some particular business.”\n",
      "\", N, N\n",
      "\" “Oh, only tonight. Are you coming over to speak to Julius?” \n",
      "\", N, P\n",
      "\"`Warn him that the man he has made his enemy is in a frenzy, and that he doesn't know him if     he makes light of his approach. Tell him that he is on the road—I know he is!—and hurrying on.     Urge him to get away while there is time—if there is time—and not to meet him yet. A     month or so will make years of difference. Let them not encounter, through me. Anywhere but     there! Any time but now! Let his foe follow him, and find him for himself, but not through     me!There is enough upon my head without.´ \n",
      "\", P, N\n",
      "\"Amid all these exciting disquietudes, Endymion pursued a life of enjoyment, but also of      observation and much labour. He lived more and more with the Montforts, but the friendship of      Berengaria was not frivolous. Though she liked him to be seen where he ought to figure, and      required a great deal of attention herself, she ever impressed on him that his present life      was only a training for a future career, and that his mind should ever be fixed on the      attainment of a high position. Particularly she impressed on him the importance of being a      linguist. “There will be a reaction some day from all this political economy,” she would say,      “and then there will be no one ready to take the helm.” Endymion was not unworthy of the      inspiring interest which Lady Montfort took in him. The terrible vicissitudes of his early      years had gravely impressed his character. Though ambitious, he was prudent; and, though born      to please and be pleased, he was sedulous and self-restrained. Though naturally deeply      interested in the fortunes of his political friends, and especially of Lord Roehampton and Mr.      Wilton, a careful scrutiny of existing circumstances had prepared him for an inevitable      change; and, remembering what was their position but a few years back, he felt that his sister      and himself should be reconciled to their altered lot, and be content. She would still be a      peeress, and the happy wife of an illustrious man; and he himself, though he would have to      relapse into the drudgery of a public office, would meet duties the discharge of which was      once the object of his ambition, coupled now with an adequate income and with many      friends.\n",
      "\", P, P\n",
      "\"'He was a man of untidy habits—very untidy and careless. He was left with good prospects, but     he threw away his chances, lived for some time in poverty with occasional short intervals of     prosperity, and finally, taking to drink, he died. That is all I can gather.'\n",
      "\", N, N\n",
      "\"\"Silent as a stone.\"\n",
      "\", N, N\n",
      "\"The old man laid down his hand to light a cigar. He didn't pick it up at once, but sat back     for a moment in his chair, with his fingers tapping on his knees.\n",
      "\", N, N\n",
      "\"`Sisters, perhaps?´ quoth Carker. \n",
      "\", N, N\n",
      "\"'You have an extraordinary genius for minutiæ,' I remarked.\n",
      "\", P, P\n",
      "\"The dame looked on her carefully, and remembered how she had faltered and changed      countenance that other day, when she had charged her with being minded to flee; and now she      saw her with wondering face, and in no wise confused or afraid of guilt, as it seemed; so she      believed her tale, and being the more at ease thereby, her wrath ran off her, and she spake      altogether pleasantly to Birdalone, and said: Now I have had my gird at thee, my servant, I      must tell thee that in sooth it is not all for nothing that thou hast had these months of      rest; for verily thou hast grown more of a woman thereby, and hast sleekened and rounded much.      Albeit, the haysel will wait no longer for us, and the day after tomorrow we must fall to on      it. But when that is done, thou shalt be free to do thy green gown, or what thou wilt, till      wheat harvest is toward; and thereafter we shall see to it. Or what sayest thou?\n",
      "\", N, P\n",
      "\" “He may live a month,” said Lady Marnev; “he cannot live two. It is the greatest of      secrets; known at this moment only to four individuals, and I communicate it to you, my dear      Charles, in that absolute confidence which I hope will always subsist between us, because it      is an event that may greatly affect your career.”\n",
      "\", P, P\n",
      "\"\"Robert Audley is mad,\" she said, decisively. \"What is one of the strangest diagnostics of     madness—what is the first appalling sign of mental aberration? The mind becomes stationary; the     brain stagnates; the even current of reflection is interrupted; the thinking power of the brain     resolves itself into a monotone. As the waters of a tideless pool putrefy by reason of their     stagnation, the mind becomes turbid and corrupt through lack of action; and the perpetual     reflection upon one subject resolves itself into monomania. Robert Audley is a monomaniac. The     disappearance of his friend, George Talboys, grieved and bewildered him. He dwelt upon this one     idea until he lost the power of thinking of anything else. The one idea looked at perpetually     became distorted to his mental vision. Repeat the commonest word in the English language twenty     times, and before the twentieth repetition you will have begun to wonder whether the word which     you repeat is really the word you mean to utter. Robert Audley has thought of his friend's     disappearance until the one idea has done its fatal and unhealthy work. He looks at a common     event with a vision that is diseased, and he distorts it into a gloomy horror engendered of his     own monomania. If you do not want to make me as mad as he is, you must never let me see him     again. He declared to-night that George Talboys was murdered in this place, and that he will     root up every tree in the garden, and pull down every brick in the house in search for—\"\n",
      "\", N, N\n",
      "\"`My dear Paul! He's quite a Dombey!´ \n",
      "\", N, N\n",
      "\"He stared at me blankly; then, as the notion dawned on his fuddled brain, his face broke into     the vacant drunkard's smile.\n",
      "\", N, N\n",
      "\"Here he performs afternoon service every Sunday, and administers                                        the Sacrament once in every three months. His audience is                                        not large; and, had they been so, he could not have                                        accommodated them: but  enough come to fill his                                        six pews, and, on the front seat of those devoted to the                                        poor is always to be seen our old friend Mr. Bunce, decently                                        arrayed in his bedesman's gown.\n",
      "\", P, P\n",
      "\"There was very little to see in the drawing-room; and George Talboys soon grew tired of     staring at the handsome modern furniture, and at a few pictures of some of the     Academicians.\n",
      "\", N, N\n",
      "\" Blind to her, thinking only of himself, he slipped his arm softly round her waist, and drew     her to him. Her heart fainted, feeling herself taken. But then, his arm was so strong, she     quailed under its powerful close grasp. She died a little death, and was drawn against him as     they walked down the stormy darkness. He seemed to balance her perfectly in opposition to     himself, in their dual motion of walking. So, suddenly, he was liberated and perfect, strong,     heroic. \n",
      "\", P, P\n",
      "\"I took my head in my hands and thought. There must be some way of reading this riddle. What     did Scudder mean by steps? I thought of dock steps, but if he had meant that I didn't think he     would have mentioned the number. It must be some place where there were several staircases, and     one marked out from the others by having thirty-nine steps.\n",
      "\", N, N\n",
      "\"The church reformer soon found himself tête à tête with                                        the archdeacon in that same room, in that sanctum sanctorum                                        of the rectory, to which we have already been introduced. As                                        he entered he heard the click of a certain patent lock, but                                        it struck him with no surprise: the worthy clergyman was no                                        doubt hiding from eyes profane his last much-studied sermon,                                        for the archdeacon, though he preached but seldom, was                                        famous for his sermons. No room, Bold thought, could have                                        been more becoming for a dignitary of the church; each wall                                        was loaded with theology; over each separate book-case was                                        printed in small gold letters the names of those great                                        divines whose works were ranged beneath: beginning from the                                        early fathers in due chronological order, there were to be                                        found the precious labours of the chosen servants of the                                        church down to the last pamphlet written in opposition to                                        the consecration of Dr. Hampden; and raised above this were                                        to be seen the busts of the greatest among the great:                                        Chrysostom,  St. Augustine, Thomas à Becket,                                        Cardinal Wolsey, Archbishop Laud, and Dr. Philpotts.\n",
      "\", N, N\n",
      "\" “Let the dead bury their dead—don’t go and bury yourself along with them—that’s what I tell     you. I know you well enough.” \n",
      "\", N, P\n",
      "\"He remained like this for days and weeks. At length, lying, the faint feeble semblance of a     man, upon his bed, and speaking in a voice so low that they could only hear him by listening     very near to his lips, he became quiet. It was dimly pleasant to him now, to lie their, with     the window open, looking out at the summer sky and the trees: and, in the evening, at the     sunset. To watch the shadows of the clouds and leaves, and seem to feel a sympathy with     shadows. It was natural that he should. To him, life and the world were nothing else. \n",
      "\", N, N\n",
      "\"`I mean, Papa, what can it do?´ returned Paul, folding his arms (they were hardly long enough     to fold), and looking at the fire, and up at him, and at the fire, and up at him again. \n",
      "\", N, N\n",
      "\"`Physicians,´ observed Bunsby, `was in vain.´ \n",
      "\", N, N\n",
      "\"\"I never meant you to know.\"\n",
      "\", N, P\n",
      "\"\"To be sure, we must Auntie.\"\n",
      "\", N, P\n",
      "\"Very often he could even hear their words, especially the landlord's, for he spoke in a     coarse, loud voice, and had a more boastful manner than any of his customers.\n",
      "\", P, P\n",
      "\"I finished Turnbull's bread and cheese, and pretty soon I had finished the stones. The next     step was what puzzled me. I could not keep up this roadmaking business for long. A merciful     Providence had kept Mr Turnbull indoors, but if he appeared on the scene there would be     trouble. I had a notion that the cordon was still tight round the glen, and that if I walked in     any direction I should meet with questioners. But get out I must. No man's nerve could stand     more than a day of being spied on.\n",
      "\", N, N\n",
      "\" “You speak of Mr Morley—”\n",
      "\", N, P\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def truncate_sentence(sentence, max_length=512):\n",
    "    tokens = tokenizer.encode(sentence, truncation=True, max_length=max_length, add_special_tokens=True)\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "bert_model = pipeline(\"sentiment-analysis\",model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0)                           \n",
    "\n",
    "def bert_sentiment(sentence):\n",
    "    truncated_sentence = truncate_sentence(sentence)\n",
    "    result = bert_model(truncated_sentence)\n",
    "    if result[0]['label']=='POSITIVE':\n",
    "        return 'P'\n",
    "    else:\n",
    "        return 'N'\n",
    "\n",
    "with open(\"en.txt\", \"r\") as f:\n",
    "    sentences = f.readlines()\n",
    "    \n",
    "random_sentences = random.sample(sentences, 100)\n",
    "    \n",
    "\n",
    "def compare_sentiment_analysis(sentences):\n",
    "    results = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        ResNB = positive_or_not(sentence)\n",
    "        ResBERT = bert_sentiment(sentence)\n",
    "        results.append((sentence,ResNB,ResBERT))\n",
    "\n",
    "    for sentence,ResNB,ResBERT in results:\n",
    "        print(f'\"{sentence}\", {ResNB}, {ResBERT}')\n",
    "\n",
    "    with open(\"sent_comp.txt\", \"w\") as file:\n",
    "        for sentence, ResNB, ResBERT in results:\n",
    "            file.write(f'\"{sentence}\", {ResNB}, {ResBERT}\\n')\n",
    "\n",
    "compare_sentiment_analysis(random_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49492633-cfa3-4b0c-9086-37d3a70b0223",
   "metadata": {},
   "source": [
    "### Exercise 1.3 (5 points): \n",
    "Calculate how often the two models agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63358417-6661-4c5b-a0b6-56a04c30fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two models agree 73.00% of the time.\n"
     ]
    }
   ],
   "source": [
    "def compare_anaysis(sentences) :\n",
    "    agree_count = 0\n",
    "    total_count = len(sentences)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        ResNB = positive_or_not(sentence)\n",
    "        ResBERT = bert_sentiment(sentence)\n",
    "        if ResNB == ResBERT:\n",
    "            agree_count += 1\n",
    "\n",
    "    agree_percentage = (agree_count / total_count) * 100\n",
    "    return agree_percentage\n",
    "\n",
    "agree_percentage = compare_anaysis(random_sentences)\n",
    "print(f\"The two models agree {agree_percentage:.2f}% of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec61c27-6bd8-47bd-8e2e-89f304e22009",
   "metadata": {},
   "source": [
    "### Exercise 1.4 (20 points):\n",
    "\n",
    "If the models agree, do they provide the right response? If not, which model is wrong? Briefly discuss the results from some examples from the selection (5 examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ecaa2-fc39-4018-a968-f6644b048528",
   "metadata": {},
   "source": [
    "1. Sentence:\"Egremont smiled. 'Your Convention is in its bloom, or rather its bud,' he said; 'all is fresh and pure now; but a little while and it will find the fate of all popular assemblies. You will have factions.'\"\n",
    "\n",
    "Outcome: Both models (NB and BERT): Positive (P)\n",
    "\n",
    "Discussion: The start of the sentence feels positive, talking about new beginnings, but then it becomes more cynical, predicting future problems. Both models tagged it as positive, probably because of \"fresh and pure.\" Both models agree, but they miss the shift in sentiment. It feels more neutral-to-negative at the end, so they’re not completely right, but at least they agree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c517f-89aa-4fb0-ad6b-929d3b4b0301",
   "metadata": {},
   "source": [
    "2. Sentence:\"And yet you want to see new lands?\" he pursued. \"What is it you want to see there?\"\n",
    "\n",
    "Outcome: Both models: Positive (P)\n",
    "\n",
    "Discussion:This sentence is quite neutral—there is no strong emotion. It's just a question. Both models are wrong here because they marked it as positive. There is nothing happy or sad about it, just a simple question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574a3ec-8060-4b31-8d9a-33b89243dd15",
   "metadata": {},
   "source": [
    "3. Sentence:\"Yes. Because, if women never see the serpent's face, neither do they ever scent the smell of the paradise roses; and it will be hard for you to die without a single rose d'amour in your pretty breast, poor little Bébée?\"\n",
    "\n",
    "Outcome: NB: Negative (N) BERT: Positive (P)\n",
    "\n",
    "Discussion:This sentence has mixed emotions. The \"serpent's face\" part feels dark and warning, but then it changes to a more romantic and affectionate tone with \"pretty breast\" and \"poor little Bébée.\"  I think Naive Bayes is closer to the truth in this case,as the darker part makes the sentence feel a bit negative overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70501a27-e60a-4370-ba9c-946c0132230d",
   "metadata": {},
   "source": [
    "4. Sentence:\"Then we must be quick,\" she answered. \"Come.\"\n",
    "\n",
    "Outcome: NB: Negative (N) BERT: Positive (P)\n",
    "\n",
    "Discussion:This sentence is neutral, but there is a sense of urgency. It’s not really positive or negative, just someone telling another to hurry. I think BERT is more accurate here, seeing it as positive because it has an action-oriented tone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c940cf1-640f-40c0-b4fe-eeac34c3aa08",
   "metadata": {},
   "source": [
    "5. Sentence:\"When she had thus brought him all she had, and he to please her had sat down to the simple food, she gathered a spray of roses and set it in a pot beside him, then left him and went and stood at a little distance, waiting, with her hands lightly crossed on her chest, to see if there were anything that he might want.\"\n",
    "\n",
    "Outcome: Both models: Negative (N)\n",
    "\n",
    "Discussion:This sentence is subtle—not clearly sad, but there’s a quiet sense of resignation. Both models tagged it as negative, which makes sense because the tone is definitely subdued and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd5aad-4af0-4035-abe5-1811dd5bd25c",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "When the models agree, they usually get it right for simple sentences, but they can miss the mark with more complex ones.\n",
    "When they disagree, Naive Bayes sometimes picks up on the subtler, darker emotions, while BERT tends to see things more positively or romantically when the sentiment is mixed.\n",
    "Overall, both models are useful, but they have their own weaknesses. Sometimes they both get it right, but other times they miss the deeper meaning, especially in more complicated sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac1536-1314-405e-8a4e-a3024ed19c63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2 (Text classification)\n",
    "\n",
    "In the second part of the assignment, you will be working on text classification. We will employ the same data set that we used for the TF-IDF example in lecture 10, provided by scikit-learn. It is the dataset called `fetch_20newsgroups`.\n",
    "\n",
    "The goal of this assignment is to learn how to perform basic text classification using scikit-learn, but also to see whether named entities can positively contribute to a better classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abfbda3-9745-4ce2-b885-644a9ef18692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1102, 1657)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cats = ['alt.atheism', 'sci.space', 'comp.graphics']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats)\n",
    "\n",
    "len(newsgroups_test['data']),len(newsgroups_train['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543cba83-c327-4332-bfd7-a090842d481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 248, 165, 165)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This whole cell is just to \n",
    "\n",
    "whole_train_instances = newsgroups_train['data']\n",
    "whole_y_train = [newsgroups_train['target_names'][el] for el in newsgroups_train['target']]\n",
    "\n",
    "train_instances, _, y_train, _ = train_test_split(whole_train_instances, whole_y_train, train_size=0.15)\n",
    "\n",
    "whole_test_instances = newsgroups_test['data']\n",
    "whole_y_test = [newsgroups_test['target_names'][el] for el in newsgroups_test['target']]\n",
    "\n",
    "test_instances, _, y_test, _ = train_test_split(whole_test_instances, whole_y_test, train_size=0.15)\n",
    "\n",
    "len(train_instances), len(y_train), len(test_instances), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca63ae4-33ab-449a-a050-c609c25952f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 414, 165, 165)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The goal of this cell is just to get a smaller subset of the corpus,\n",
    "#as the third exercise of this part can be quite computationally expensive.\n",
    "#If it is too expensive for your computers, feel free to use Google colab or to just contact Manex.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "whole_train_instances = newsgroups_train['data']\n",
    "whole_y_train = [newsgroups_train['target_names'][el] for el in newsgroups_train['target']]\n",
    "\n",
    "train_instances, _, y_train, _ = train_test_split(whole_train_instances, whole_y_train, train_size=0.25)\n",
    "\n",
    "whole_test_instances = newsgroups_test['data']\n",
    "whole_y_test = [newsgroups_test['target_names'][el] for el in newsgroups_test['target']]\n",
    "\n",
    "test_instances, _, y_test, _ = train_test_split(whole_test_instances, whole_y_test, train_size=0.15)\n",
    "\n",
    "len(train_instances), len(y_train), len(test_instances), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147920a-93df-4217-b294-66063a00cc31",
   "metadata": {},
   "source": [
    "### Exercise 2.1 (15 points):\n",
    "\n",
    "In this first exercise, you need to use a Bag of Words representation for the articles from `fetch_20newsgroups`. Vectorize the news articles (please use `CountVectorizer` with its default parameters) and train a Logistic Regression model on the training data.\n",
    "\n",
    "After that, apply the trained model on the test data and check the performance by printing the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90317e3-4b88-436c-bfa5-0692d78f2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.93      0.86      0.89        49\n",
      "comp.graphics       0.83      0.92      0.87        60\n",
      "    sci.space       0.87      0.84      0.85        56\n",
      "\n",
      "     accuracy                           0.87       165\n",
      "    macro avg       0.88      0.87      0.87       165\n",
      " weighted avg       0.88      0.87      0.87       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_instances)\n",
    "X_test = vectorizer.transform(test_instances)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=newsgroups_test['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8aea3-01f1-4e64-9193-add441703ffa",
   "metadata": {},
   "source": [
    "### Exercise 2.2 (15 points):\n",
    "\n",
    "You should do the same as in Exercise 2.1, but instead of using a Bag of Words, you should normalize these frequencies with the inverse document frequency. Please, use a relevant package from `sklearn`. You should print the classification report, as above. Are results better? Why does this happen? Think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90078982-d0ec-4881-9bc2-afa6b46101b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.98      0.84      0.90        49\n",
      "comp.graphics       0.89      0.93      0.91        60\n",
      "    sci.space       0.85      0.91      0.88        56\n",
      "\n",
      "     accuracy                           0.90       165\n",
      "    macro avg       0.91      0.89      0.90       165\n",
      " weighted avg       0.90      0.90      0.90       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_instances)\n",
    "X_test = vectorizer.transform(test_instances)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=newsgroups_test['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8b93d-0676-416f-b263-1f99683e2795",
   "metadata": {},
   "source": [
    "TF-IDF often performs better than Bag of Words because it down-weights common words and highlights unique, category-defining terms. This makes the model focus on more relevant features, improving classification accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b324b3-3956-4161-bada-781fadd9a0c8",
   "metadata": {},
   "source": [
    "### Exercise 2.3 (20 points):\n",
    "\n",
    "We would now like to know whether the use of Named Entities can help in text classification. Currently, if a multiword Named entity is present in the corpus, the bag of words interprets them as two separate words. We would like the model to recognize also the whole named entities.\n",
    "\n",
    "In order to test this, we would like you to extract named entities, and somehow include those multiword named entities, as extra words. For instance, assuming that we have a 6 word dictionary,\n",
    "\n",
    "```\n",
    "dict = [\"i\":0,\n",
    "         \"house\":1,\n",
    "         \"like\":2,\n",
    "         \"new\":3,\n",
    "         \"plant\":4,\n",
    "         \"york\":5]\n",
    "```\n",
    "\n",
    "we would return this as the representation of this sentence: `I like New York`\n",
    "\n",
    "`bag_of_words = [1, 0, 1, 1, 0, 1]`\n",
    "\n",
    "Now, we would like to have an extra word for named entities in the dictionary, which would represent the word `New York`, such as:\n",
    "\n",
    "```\n",
    "new_dict = [\"i\":0,\n",
    "         \"house\":1,\n",
    "         \"like\":2,\n",
    "         \"new\":3,\n",
    "         \"plant\":4,\n",
    "         \"york\":5,\n",
    "         \"new york\": 6]\n",
    "```\n",
    "\n",
    "`new_bag_of_words = [1, 0, 1, 1, 0, 1, 1]`\n",
    "\n",
    "A trick can be to use an underscore to join multiword entities, such as `new_york`.\n",
    "\n",
    "---\n",
    "\n",
    "Train a Logistic Regression using CountVectorizer, where we also include Named Entities. Do results improve? Check them with classification report, just like in the previous two exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f547f96-8bb0-49a2-bf1d-8630649dc85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/anaconda3/lib/python3.12/site-packages/numpy-1.26.4.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6de0b72b-c029-4bb1-a56f-e82472a6f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  alt.atheism       0.93      0.84      0.88        49\n",
      "comp.graphics       0.79      0.92      0.85        53\n",
      "    sci.space       0.92      0.86      0.89        63\n",
      "\n",
      "     accuracy                           0.87       165\n",
      "    macro avg       0.88      0.87      0.87       165\n",
      " weighted avg       0.88      0.87      0.87       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text.replace(\" \", \"_\") for ent in doc.ents]\n",
    "    return text + \" \" + \" \".join(entities)\n",
    "\n",
    "cats = ['alt.atheism', 'sci.space', 'comp.graphics']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats)\n",
    "\n",
    "train_instances, _, y_train, _ = train_test_split(newsgroups_train['data'], \n",
    "                                                  newsgroups_train['target'], \n",
    "                                                  train_size=0.25)\n",
    "\n",
    "test_instances, _, y_test, _ = train_test_split(newsgroups_test['data'], \n",
    "                                                newsgroups_test['target'], \n",
    "                                                train_size=0.15)\n",
    "\n",
    "train_instances_with_ner = [extract_named_entities(text) for text in train_instances]\n",
    "test_instances_with_ner = [extract_named_entities(text) for text in test_instances]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_instances_with_ner)\n",
    "X_test = vectorizer.transform(test_instances_with_ner)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=newsgroups_test['target_names']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05f69a-46e9-4258-9be1-273f9ae90fc9",
   "metadata": {},
   "source": [
    "The addition of named entity recognition (NER) didn’t significantly improve my model's performance.\n",
    "\n",
    "Comparison: alt.atheism: Precision dropped from 0.98 to 0.93.  comp.graphics: Precision slightly decreased from 0.89 to 0.79.  sci.space: Precision improved from 0.85 to 0.92.\n",
    "\n",
    "Discussion：Why might this happen?\n",
    "Irrelevant Named Entities: The NER might have captured entities that weren’t helpful for the classification.\n",
    "Feature Overload: Adding too many features can introduce noise instead of improving the model.\n",
    "Model Limitation: Logistic Regression might not be the best choice to take full advantage of these additional features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
